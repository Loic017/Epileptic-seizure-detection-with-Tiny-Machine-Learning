{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data and Train Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\loicl\\Documents\\UniWork\\Year 3\\Dissertation\\TinyML-for-Epileptic-Seizures\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset, SubsetRandomSampler\n",
    "from torch.utils.data.dataset import random_split\n",
    "from transformers import get_scheduler, AdamW\n",
    "from datasets import load_metric\n",
    "from torchsummary import summary\n",
    "from kfold_functions import reset_weights\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd;\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "\n",
    "seed_number = 69 # 69 for absence and tonic-clonic / 21 for general\n",
    "# torch.manual_seed(seed_number)\n",
    "np.random.seed(seed_number)\n",
    "random.seed(seed_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "seizure_type = \"general\"\n",
    "main_folder_path = \"melspectrograms/\"\n",
    "path = main_folder_path + seizure_type + \"/\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, data, transform=None, target_transform=None):\n",
    "        self.x, self.y = data\n",
    "        self.n_samples = len(self.x)\n",
    "\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample_x, sample_y = self.x[idx], self.y[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            sample_x = self.transform(sample_x)\n",
    "\n",
    "        if self.target_transform:\n",
    "            sample_y = self.target_transform(sample_y)\n",
    "\n",
    "        return sample_x.float(), sample_y.float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "train_x = np.load(f\"{path}/imb_{seizure_type}_x.npy\")\n",
    "train_y = np.load(f\"{path}/imb_{seizure_type}_y.npy\")\n",
    "\n",
    "validation_x = np.load(f\"{path}/validation_{seizure_type}_x.npy\")\n",
    "validation_y = np.load(f\"{path}/validation_{seizure_type}_y.npy\")\n",
    "\n",
    "test_x = np.load(f\"{path}/test_{seizure_type}_x.npy\")\n",
    "test_y = np.load(f\"{path}/test_{seizure_type}_y.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3745 1070 534\n",
      "Total: 5349\n"
     ]
    }
   ],
   "source": [
    "print(len(train_y), len(validation_y), len(test_y))\n",
    "print(f\"Total: {len(train_y) + len(validation_y) + len(test_y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset(\n",
    "    (train_x, train_y),\n",
    "    transform=torch.tensor,\n",
    "    target_transform=torch.tensor,\n",
    ")\n",
    "validation_dataset = Dataset(\n",
    "    (validation_x, validation_y),\n",
    "    transform=torch.tensor,\n",
    "    target_transform=torch.tensor,\n",
    ")\n",
    "test_dataset = Dataset(\n",
    "    (test_x, test_y),\n",
    "    transform=torch.tensor,\n",
    "    target_transform=torch.tensor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "Mobilenet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "class SZModel(nn.Module):\n",
    "    def __init__(self, l1=128):\n",
    "        super(SZModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, (3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(\n",
    "            16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
    "        )\n",
    "        self.hardswish = nn.Hardswish()\n",
    "        self.conv1_2 = nn.Conv2d(\n",
    "            16, 16, (3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
    "        )\n",
    "        self.ReLU = nn.ReLU()\n",
    "\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                16, 16, (3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(\n",
    "                16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, (1, 1), stride=(1, 1), padding=(0, 0), bias=False),\n",
    "            nn.BatchNorm2d(\n",
    "                16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            16, 16, (3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(\n",
    "            16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
    "        )\n",
    "        self.hardswish = nn.Hardswish()\n",
    "\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                16, 16, (3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(\n",
    "                16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, (1, 1), stride=(1, 1), padding=(0, 0), bias=False),\n",
    "            nn.BatchNorm2d(\n",
    "                16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        self.globalaveragepool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.classif_block = nn.Sequential(\n",
    "            nn.Linear(16, l1),\n",
    "            nn.Hardswish(),\n",
    "            nn.Dropout(p=0.3, inplace=True),\n",
    "            nn.Linear(l1, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.hardswish(x)\n",
    "        x = self.conv1_2(x)\n",
    "        x = self.ReLU(x)\n",
    "\n",
    "        x = self.block1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.hardswish(x)\n",
    "\n",
    "        x = self.block2(x)\n",
    "\n",
    "        x = self.globalaveragepool(x)\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = self.classif_block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 20, 13]             144\n",
      "       BatchNorm2d-2           [-1, 16, 20, 13]              32\n",
      "         Hardswish-3           [-1, 16, 20, 13]               0\n",
      "            Conv2d-4            [-1, 16, 10, 7]           2,304\n",
      "              ReLU-5            [-1, 16, 10, 7]               0\n",
      "            Conv2d-6            [-1, 16, 10, 7]             144\n",
      "       BatchNorm2d-7            [-1, 16, 10, 7]              32\n",
      "              ReLU-8            [-1, 16, 10, 7]               0\n",
      "            Conv2d-9            [-1, 16, 10, 7]             256\n",
      "      BatchNorm2d-10            [-1, 16, 10, 7]              32\n",
      "           Conv2d-11             [-1, 16, 5, 4]           2,304\n",
      "      BatchNorm2d-12             [-1, 16, 5, 4]              32\n",
      "        Hardswish-13             [-1, 16, 5, 4]               0\n",
      "           Conv2d-14             [-1, 16, 5, 4]             144\n",
      "      BatchNorm2d-15             [-1, 16, 5, 4]              32\n",
      "             ReLU-16             [-1, 16, 5, 4]               0\n",
      "           Conv2d-17             [-1, 16, 5, 4]             256\n",
      "      BatchNorm2d-18             [-1, 16, 5, 4]              32\n",
      "AdaptiveAvgPool2d-19             [-1, 16, 1, 1]               0\n",
      "          Flatten-20                   [-1, 16]               0\n",
      "           Linear-21                  [-1, 128]           2,176\n",
      "        Hardswish-22                  [-1, 128]               0\n",
      "          Dropout-23                  [-1, 128]               0\n",
      "           Linear-24                    [-1, 2]             258\n",
      "================================================================\n",
      "Total params: 8,178\n",
      "Trainable params: 8,178\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.18\n",
      "Params size (MB): 0.03\n",
      "Estimated Total Size (MB): 0.21\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = SZModel()\n",
    "model = model.to(device)\n",
    "# model\n",
    "summary(model, (1, 40, 26), batch_size=-1, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold Cross Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-use-k-fold-cross-validation-with-pytorch.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background: 4100, general Seizure: 1249, Total: 5349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_folds = 10\n",
    "n_fold_epochs = 200\n",
    "k_fold_batch_size = 512\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "acc_results = {}  # For accuracy\n",
    "cm_results = {}  # For confusion matrix\n",
    "metric_results = {}\n",
    "actual_labels = {}\n",
    "predicted_labels = {}\n",
    "roc_auc_results = {}\n",
    "gmeans_results = {}\n",
    "\n",
    "dataset = ConcatDataset([train_dataset, validation_dataset, test_dataset])\n",
    "\n",
    "a, b, c = 0, 0, 0\n",
    "for j in dataset:\n",
    "    if j[1] == (1.0):\n",
    "        b += 1\n",
    "    else:\n",
    "        a += 1\n",
    "    c += 1\n",
    "print(f\"Background: {a}, {seizure_type} Seizure: {b}, Total: {c}\")\n",
    "\n",
    "kfold = KFold(n_splits=n_folds, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "Total before SMOTE: 5349\n",
      "Length of trainloader before SMOTE: 4814\n",
      "Length of trainloader: 7386\n",
      "Length of testloader: 535\n",
      "Total: 7921\n",
      "Training process has finished\n",
      "Starting testing\n",
      " \n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 0-dimensional, but 1 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 220\u001b[0m\n\u001b[0;32m    218\u001b[0m y_true \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m actual_test:\n\u001b[1;32m--> 220\u001b[0m     y_true\u001b[38;5;241m.\u001b[39mappend(\u001b[43mi\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_true)\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_score)\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 0-dimensional, but 1 were indexed"
     ]
    }
   ],
   "source": [
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "    # Print\n",
    "    print(f\"FOLD {fold}\")\n",
    "    print(\"--------------------------------\")\n",
    "\n",
    "    # Sample elements randomly from a given list of ids, no replacement.\n",
    "    train_subsampler = SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = SubsetRandomSampler(test_ids)\n",
    "\n",
    "    # Define data loaders for training and testing data in this fold\n",
    "    trainloader = DataLoader(\n",
    "        dataset, batch_size=k_fold_batch_size, sampler=train_subsampler\n",
    "    )\n",
    "    testloader = DataLoader(dataset, batch_size=1, sampler=test_subsampler)\n",
    "\n",
    "    print(f\"Total before SMOTE: {len(train_subsampler) + len(test_subsampler)}\")\n",
    "    print(f\"Length of trainloader before SMOTE: {len(train_subsampler)}\")\n",
    "    # Copy trainloader to another variable\n",
    "    trainloader_copy = trainloader\n",
    "    del trainloader\n",
    "\n",
    "    # Get trainloader and apply smote\n",
    "    train_x, train_y = [], []\n",
    "    for i, data in enumerate(trainloader_copy):\n",
    "        inputs, targets = data\n",
    "        for i in range(len(inputs)):\n",
    "            train_x.append(inputs[i].cpu().numpy())\n",
    "            train_y.append(targets[i].cpu().numpy())\n",
    "    train_x = np.array(train_x)\n",
    "    train_y = np.array(train_y)\n",
    "\n",
    "    one_dim = []\n",
    "    for i in train_x:\n",
    "        one_dim.append(i)\n",
    "    one_dim = np.array(one_dim)\n",
    "\n",
    "    # Flatten to make it one dim\n",
    "    shape = one_dim.shape\n",
    "    one_dim_reshaped = np.reshape(one_dim, (shape[0], shape[1] * shape[2]))\n",
    "\n",
    "    # Apply Smote\n",
    "    x, y = SMOTE(sampling_strategy=\"not majority\", random_state=42).fit_resample(\n",
    "        one_dim_reshaped, train_y\n",
    "    )\n",
    "\n",
    "    # Reshape back to 2D\n",
    "    x = np.reshape(x, (x.shape[0], shape[1], shape[2]))\n",
    "\n",
    "    one_channel = []\n",
    "    for i in x:\n",
    "        one_channel.append([i])\n",
    "    x = np.array(one_channel)\n",
    "\n",
    "    # Back into dataloader\n",
    "    train_dataset = Dataset(\n",
    "        (x, y),\n",
    "        transform=torch.tensor,\n",
    "        target_transform=torch.tensor,\n",
    "    )\n",
    "\n",
    "    # Make test set one channel\n",
    "    test_x, test_y = [], []\n",
    "\n",
    "    testloader_copy = testloader\n",
    "    del testloader\n",
    "\n",
    "    for i, data in enumerate(testloader_copy):\n",
    "        inputs, targets = data\n",
    "        for i in range(len(inputs)):\n",
    "            test_x.append(inputs[i].cpu().numpy())\n",
    "            test_y.append(targets[i].cpu().numpy())\n",
    "    test_x = np.array(test_x)\n",
    "    test_y = np.array(test_y)\n",
    "\n",
    "    test_one_channel = []\n",
    "    for i in test_x:\n",
    "        test_one_channel.append([i])\n",
    "    test_x = np.array(test_one_channel)\n",
    "\n",
    "    test_dataset = Dataset(\n",
    "        (test_x, test_y),\n",
    "        transform=torch.tensor,\n",
    "        target_transform=torch.tensor,\n",
    "    )\n",
    "\n",
    "    trainloader = DataLoader(train_dataset, batch_size=k_fold_batch_size, shuffle=True)\n",
    "    testloader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "    print(f\"Length of trainloader: {len(train_dataset)}\")\n",
    "    print(f\"Length of testloader: {len(test_subsampler)}\")\n",
    "    print(f\"Total: {len(train_dataset) + len(test_subsampler)}\")\n",
    "\n",
    "    # Init the neural network\n",
    "    network = SZModel()\n",
    "    network.to(device)\n",
    "    network.apply(reset_weights)\n",
    "\n",
    "    # Initialize optimizer\n",
    "    optimizer = torch.optim.Adam(network.parameters(), lr=5e-5)\n",
    "\n",
    "    # Run the training loop for defined number of epochs\n",
    "    network.train()\n",
    "    for epoch in range(0, n_fold_epochs):\n",
    "\n",
    "        # Print epoch\n",
    "        # print(f\"Starting epoch {epoch+1}\")\n",
    "\n",
    "        # Set current loss value\n",
    "        current_loss = 0.0\n",
    "\n",
    "        # Iterate over the DataLoader for training data\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "            # Get inputs\n",
    "            inputs, targets = data\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            targets = targets.to(torch.int64)\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Perform forward pass\n",
    "            outputs = network(inputs)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_fn(outputs, targets)\n",
    "\n",
    "            # Perform backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Perform optimization\n",
    "            optimizer.step()\n",
    "\n",
    "            # Print statistics\n",
    "            current_loss += loss.item()\n",
    "            if i % 500 == 499:\n",
    "                print(\"Loss after mini-batch %5d: %.3f\" % (i + 1, current_loss / 500))\n",
    "                current_loss = 0.0\n",
    "\n",
    "    # Process is complete.\n",
    "    print(\"Training process has finished\")\n",
    "\n",
    "    # Print about testing\n",
    "    print(\"Starting testing\")\n",
    "    print(\" \")\n",
    "\n",
    "    # Saving the model\n",
    "    save_path = f\"model/kfold/{seizure_type}/{seizure_type}-fold-{fold}.pth\"\n",
    "    torch.save(network.state_dict(), save_path)\n",
    "\n",
    "    # Evaluationfor this fold\n",
    "    correct, total = 0, 0\n",
    "    actual_test, predicted_test = [], []\n",
    "    tp_fn_tn_fp = [0, 0, 0, 0]\n",
    "    network.eval()\n",
    "    with torch.no_grad():\n",
    "        # Iterate over the test data and generate predictions\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "\n",
    "            # Get inputs\n",
    "            inputs, targets = data\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            targets = targets.to(torch.int64)\n",
    "\n",
    "            # Generate outputs\n",
    "            outputs = network(inputs)\n",
    "\n",
    "            # Set total and correct\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "            outputs = nn.functional.softmax(outputs, dim=1)\n",
    "\n",
    "            # print(targets)\n",
    "            # print(outputs)\n",
    "            # print(\" \")\n",
    "\n",
    "            actual_test.append(targets[0].cpu().numpy())\n",
    "            predicted_test.append(outputs[0][1].cpu().numpy())\n",
    "\n",
    "            # print(outputs, targets)\n",
    "            if targets[0] == torch.tensor([1]).to(device):\n",
    "                if torch.round(outputs[0][1], decimals=4) > torch.round(\n",
    "                    outputs[0][0], decimals=4\n",
    "                ):\n",
    "                    tp_fn_tn_fp[0] += 1\n",
    "                else:\n",
    "                    tp_fn_tn_fp[1] += 1\n",
    "            elif targets[0] == torch.tensor([0]).to(device):\n",
    "                if torch.round(outputs[0][0], decimals=4) > torch.round(\n",
    "                    outputs[0][1], decimals=4\n",
    "                ):\n",
    "                    tp_fn_tn_fp[2] += 1\n",
    "                else:\n",
    "                    tp_fn_tn_fp[3] += 1\n",
    "\n",
    "        # print(tp_fn_tn_fp)\n",
    "        # Calculate Results\n",
    "        tp, fn, tn, fp = (\n",
    "            tp_fn_tn_fp[0],\n",
    "            tp_fn_tn_fp[1],\n",
    "            tp_fn_tn_fp[2],\n",
    "            tp_fn_tn_fp[3],\n",
    "        )\n",
    "\n",
    "        sensitivity = round((tp) / (tp + fn), 5)\n",
    "        specificity = round((tn) / (tn + fp), 5)\n",
    "        try:\n",
    "            precision = round((tp) / (tp + fp), 5)\n",
    "        except:\n",
    "            precision = 0\n",
    "        accuracy = round((tp + tn) / (tp + tn + fp + fn), 5)\n",
    "\n",
    "        y_score = []\n",
    "        for i in predicted_test:\n",
    "            y_score.append(i.item())\n",
    "\n",
    "        y_true = []\n",
    "        for i in actual_test:\n",
    "            y_true.append(i.item())\n",
    "\n",
    "        print(y_true)\n",
    "        print(y_score)\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_true=y_true, y_score=y_score)\n",
    "        roc_auc = metrics.auc(fpr, tpr)\n",
    "        roc_auc_score = metrics.roc_auc_score(y_true=y_true, y_score=y_score)\n",
    "\n",
    "        print(\"Roc Auc\")\n",
    "        print(roc_auc_score)\n",
    "\n",
    "        # Print Results\n",
    "        print(\"Accuracy for fold %d: %d %%\" % (fold, 100.0 * correct / total))\n",
    "        print(f\"tp_fn_tn_fp for fold {fold} is {tp_fn_tn_fp}\")\n",
    "        print(\n",
    "            f\"sensitivity {sensitivity}, specificity {specificity}, precision {precision}\"\n",
    "        )\n",
    "        print(f\"roc_auc {roc_auc}\")\n",
    "        print(f\"gmean {math.sqrt(sensitivity * specificity)}\")\n",
    "        print(\"--------------------------------\")\n",
    "\n",
    "        # Store Results\n",
    "        acc_results[fold] = 100.0 * (correct / total)\n",
    "        cm_results[fold] = tp_fn_tn_fp\n",
    "        metric_results[fold] = [sensitivity, specificity, precision]\n",
    "        predicted_labels[fold] = predicted_test\n",
    "        actual_labels[fold] = actual_test\n",
    "        roc_auc_results[fold] = roc_auc\n",
    "        gmeans_results[fold] = math.sqrt(sensitivity * specificity)\n",
    "\n",
    "# Print fold results\n",
    "print(f\"K-FOLD CROSS VALIDATION RESULTS FOR {n_folds} FOLDS\")\n",
    "print(\"--------------------------------\")\n",
    "sum = 0.0\n",
    "for key, value in acc_results.items():\n",
    "    print(f\"Fold {key}:\")\n",
    "    sum += value\n",
    "    print(f\"    (tp_fn_tn_fp) {cm_results[key]}\")\n",
    "    print(\n",
    "        f\"  sensitivity {metric_results[key][0]*100}%, specificity {metric_results[key][1]*100}%, precision {metric_results[key][2]*100}%, accuracy {round(value, 2)}%\"\n",
    "    )\n",
    "    print(\" \")\n",
    "    print(f\"  roc_auc {roc_auc_results[key]}\")\n",
    "    print(f\"  gmean {gmeans_results[key]}\")\n",
    "print(f\"Average Accuracy: {sum/len(acc_results.items())} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Tables and Save\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "rows = []\n",
    "for key, value in acc_results.items():\n",
    "    row = [\n",
    "        key,\n",
    "        round(value, 2),\n",
    "        round(metric_results[key][0] * 100, 2),\n",
    "        round(metric_results[key][1] * 100, 2),\n",
    "        round(metric_results[key][2] * 100, 2),\n",
    "        round(roc_auc_results[key] * 100, 2),\n",
    "        round(gmeans_results[key] * 100, 2),\n",
    "        f\"{cm_results[key][0]} / {cm_results[key][1]} / {cm_results[key][2]} / {cm_results[key][3]}\",\n",
    "    ]\n",
    "    rows.append(row)\n",
    "\n",
    "columns = [\n",
    "    \"fold\",\n",
    "    \"accuracy\",\n",
    "    \"sensitivity\",\n",
    "    \"specificity\",\n",
    "    \"precision\",\n",
    "    \"roc_auc\",\n",
    "    \"gmean\",\n",
    "]\n",
    "\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    rows,\n",
    "    columns=[\n",
    "        \"fold\",\n",
    "        \"accuracy\",\n",
    "        \"sensitivity\",\n",
    "        \"specificity\",\n",
    "        \"precision\",\n",
    "        \"roc_auc\",\n",
    "        \"gmean\",\n",
    "        \"tp / fn /tn / fp\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "acc_avg, sen_avg, spe_avg, pre_avg, roc_avg, gmean_avg = 0, 0, 0, 0, 0, 0\n",
    "for key, value in acc_results.items():\n",
    "    acc_avg += value\n",
    "    sen_avg += metric_results[key][0]\n",
    "    spe_avg += metric_results[key][1]\n",
    "    pre_avg += metric_results[key][2]\n",
    "    roc_avg += roc_auc_results[key]\n",
    "    gmean_avg += gmeans_results[key]\n",
    "acc_avg /= len(acc_results.items())\n",
    "sen_avg /= len(acc_results.items())\n",
    "spe_avg /= len(acc_results.items())\n",
    "pre_avg /= len(acc_results.items())\n",
    "roc_avg /= len(acc_results.items())\n",
    "gmean_avg /= len(acc_results.items())\n",
    "avg_row = [\n",
    "    \"Average\",\n",
    "    round(acc_avg, 2),\n",
    "    round(sen_avg * 100, 2),\n",
    "    round(spe_avg * 100, 2),\n",
    "    round(pre_avg * 100, 2),\n",
    "    round(roc_avg * 100, 2),\n",
    "    round(gmean_avg * 100, 2),\n",
    "    \" \",\n",
    "]\n",
    "\n",
    "df.loc[len(df)] = avg_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "      <th>precision</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>gmean</th>\n",
       "      <th>tp / fn /tn / fp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>89.35</td>\n",
       "      <td>80.47</td>\n",
       "      <td>92.14</td>\n",
       "      <td>76.30</td>\n",
       "      <td>92.20</td>\n",
       "      <td>86.11</td>\n",
       "      <td>103 / 25 / 375 / 32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>90.47</td>\n",
       "      <td>79.31</td>\n",
       "      <td>93.56</td>\n",
       "      <td>77.31</td>\n",
       "      <td>92.10</td>\n",
       "      <td>86.14</td>\n",
       "      <td>92 / 24 / 392 / 27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>91.03</td>\n",
       "      <td>74.42</td>\n",
       "      <td>96.30</td>\n",
       "      <td>86.49</td>\n",
       "      <td>90.29</td>\n",
       "      <td>84.66</td>\n",
       "      <td>96 / 33 / 391 / 15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>91.40</td>\n",
       "      <td>70.49</td>\n",
       "      <td>97.58</td>\n",
       "      <td>89.58</td>\n",
       "      <td>91.10</td>\n",
       "      <td>82.94</td>\n",
       "      <td>86 / 36 / 403 / 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>91.03</td>\n",
       "      <td>69.34</td>\n",
       "      <td>98.49</td>\n",
       "      <td>94.06</td>\n",
       "      <td>91.82</td>\n",
       "      <td>82.64</td>\n",
       "      <td>95 / 42 / 392 / 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>89.35</td>\n",
       "      <td>76.87</td>\n",
       "      <td>93.52</td>\n",
       "      <td>79.84</td>\n",
       "      <td>91.16</td>\n",
       "      <td>84.78</td>\n",
       "      <td>103 / 31 / 375 / 26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>82.80</td>\n",
       "      <td>81.75</td>\n",
       "      <td>83.13</td>\n",
       "      <td>59.88</td>\n",
       "      <td>90.34</td>\n",
       "      <td>82.44</td>\n",
       "      <td>103 / 23 / 340 / 69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>92.15</td>\n",
       "      <td>75.44</td>\n",
       "      <td>96.67</td>\n",
       "      <td>86.00</td>\n",
       "      <td>91.52</td>\n",
       "      <td>85.40</td>\n",
       "      <td>86 / 28 / 407 / 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>83.55</td>\n",
       "      <td>81.89</td>\n",
       "      <td>84.07</td>\n",
       "      <td>61.54</td>\n",
       "      <td>89.26</td>\n",
       "      <td>82.97</td>\n",
       "      <td>104 / 23 / 343 / 65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>91.01</td>\n",
       "      <td>66.38</td>\n",
       "      <td>97.85</td>\n",
       "      <td>89.53</td>\n",
       "      <td>88.34</td>\n",
       "      <td>80.59</td>\n",
       "      <td>77 / 39 / 409 / 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Average</td>\n",
       "      <td>89.21</td>\n",
       "      <td>75.64</td>\n",
       "      <td>93.33</td>\n",
       "      <td>80.05</td>\n",
       "      <td>90.81</td>\n",
       "      <td>83.87</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fold  accuracy  sensitivity  specificity  precision  roc_auc  gmean  \\\n",
       "0         0     89.35        80.47        92.14      76.30    92.20  86.11   \n",
       "1         1     90.47        79.31        93.56      77.31    92.10  86.14   \n",
       "2         2     91.03        74.42        96.30      86.49    90.29  84.66   \n",
       "3         3     91.40        70.49        97.58      89.58    91.10  82.94   \n",
       "4         4     91.03        69.34        98.49      94.06    91.82  82.64   \n",
       "5         5     89.35        76.87        93.52      79.84    91.16  84.78   \n",
       "6         6     82.80        81.75        83.13      59.88    90.34  82.44   \n",
       "7         7     92.15        75.44        96.67      86.00    91.52  85.40   \n",
       "8         8     83.55        81.89        84.07      61.54    89.26  82.97   \n",
       "9         9     91.01        66.38        97.85      89.53    88.34  80.59   \n",
       "10  Average     89.21        75.64        93.33      80.05    90.81  83.87   \n",
       "\n",
       "       tp / fn /tn / fp  \n",
       "0   103 / 25 / 375 / 32  \n",
       "1    92 / 24 / 392 / 27  \n",
       "2    96 / 33 / 391 / 15  \n",
       "3    86 / 36 / 403 / 10  \n",
       "4     95 / 42 / 392 / 6  \n",
       "5   103 / 31 / 375 / 26  \n",
       "6   103 / 23 / 340 / 69  \n",
       "7    86 / 28 / 407 / 14  \n",
       "8   104 / 23 / 343 / 65  \n",
       "9     77 / 39 / 409 / 9  \n",
       "10                       "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df.to_csv(f\"results/10_fold/{seizure_type}_2_results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
